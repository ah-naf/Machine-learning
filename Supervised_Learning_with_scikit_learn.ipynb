{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru5slheSamet"
      },
      "outputs": [],
      "source": [
        "# Scikit-learn syntax\n",
        "from sklearn.module import Model\n",
        "model = Model()\n",
        "model.fit(X, y)\n",
        "predictions = model.predict(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifying labels of unseen data**\n",
        "1. Build a model\n",
        "2. Model learns from the labeled data we pass it\n",
        "3. Pass unlabeled data to the the model as input\n",
        "4. Model predicts the labels of unseen data\n",
        "\n",
        "**Label Data = Training Data**\n"
      ],
      "metadata": {
        "id": "80SPzLd9bN_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **k-Nearest Neighbors**\n",
        "- Predict the label of a data point by\n",
        "  - Looking at the k closest labeled data points\n",
        "  - Taking a majority vote"
      ],
      "metadata": {
        "id": "NNcZp_Mogx-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using scikit-learn to fit a classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "X = churn_df[[\"total_day_charge\", \"total_eve_charge\"]].values\n",
        "y = churn_df[\"churn\"].values\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(X, y)\n",
        "\n",
        "X_new = np.array([[56.8, 17.5],\n",
        "                  [24.4, 24.1],\n",
        "                  [50.1, 10.9]])\n",
        "\n",
        "preditions = knn.predict(X_new)"
      ],
      "metadata": {
        "id": "r7latrFEbJ6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Split the data in test and training set.\n",
        "2. Fit/Train classifier on training set.\n",
        "3. Calculate accuracy using test set"
      ],
      "metadata": {
        "id": "balLl3R8kRI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "zqEngRy4kOSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Complexity**\n",
        "- Larger k = less complex model = can cause underfitting\n",
        "- Smaller k = more complex model = can lead to overfitting"
      ],
      "metadata": {
        "id": "M334pfsahQIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression**"
      ],
      "metadata": {
        "id": "y0WhIzkYlDkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# R-squared in scikit-learn\n",
        "print(reg.score(X_test, y_test))\n",
        "\n",
        "# RMSE(Root Mean Squared Error) in scikit-learn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(mean_squared_error(y_test, y_pred, squared=False))"
      ],
      "metadata": {
        "id": "FGOPz-gWhjNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross Validation**\n",
        "\n",
        "Cross validation is a technique used in machine learning to evaluate the performance of a model on unseen data. It involves dividing the available data into multiple folds or subsets, using one of these folds as a validation set, and training the model on the remaining folds. This process is repeated multiple times, each time using a different fold as the validation set. Finally, the results from each validation step are averaged to produce a more robust estimate of the model’s performance.\n",
        "\n",
        "The main purpose of cross validation is to prevent overfitting, which occurs when a model is trained too well on the training data and performs poorly on new, unseen data. By evaluating the model on multiple validation sets, cross validation provides a more realistic estimate of the model’s generalization performance, i.e., its ability to perform well on new, unseen data.\n",
        "\n",
        "- 5 folds = 5-fold CV\n",
        "- 10 folds = 10-fold CV\n",
        "- k folds = k-fold CV\n",
        "- More folds = More computatinlally expensive"
      ],
      "metadata": {
        "id": "hExZ0DNvnPZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
        "reg = LinearRegression()\n",
        "cv_results = cross_val_score(reg, X, y, cv=kf)"
      ],
      "metadata": {
        "id": "aBNOAgZhnXtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regularization**\n",
        "- Linear Regression minimizes a loss function\n",
        "- It chooses a coefficient 'a' for each feature variable, plus b\n",
        "- Large coefficients can lead to overfitting\n",
        "- Regularization: Penalize large coefficents"
      ],
      "metadata": {
        "id": "oKWG5QsIpZlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge Regression\n",
        "\n",
        "# a is numpy vector -> e.g: [1,2, 3,4]\n",
        "# Loss function = loss function + alpha * sum(a**2)\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "scores = []\n",
        "\n",
        "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
        "  ridge = Ridge(alpha=alpha)\n",
        "  ridge.fit(X_train, y_train)\n",
        "  y_pred = ridge.predict(X_test)\n",
        "  scores.append(ridge.score(X_test, y_test))\n",
        "\n",
        "print(scores)\n",
        "\n",
        "\n",
        "# Lasso Regression\n",
        "\n",
        "# Loss function = loss function + alpha * sum(abs(a))\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "for alpha in [0.1, 1.0, 10.0, 100.0, 1000.0]:\n",
        "  lasso = Lasso(alpha=alpha)\n",
        "  lasso.fit(X_train, y_train)\n",
        "  y_pred = lasso.predict(X_test)\n",
        "  scores.append(lasso.score(X_test, y_test))\n",
        "\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "W0MfTlQmp6gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lasso regression for feature selection**\n",
        "\n",
        "- Lasso can select important features of a dataset\n",
        "- Shrinks the coefficient of less important features to zero\n",
        "- Features not shrunk to zero are selected by lasso"
      ],
      "metadata": {
        "id": "gEuxlYm2p6KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "X = diabetes_df.drop('glucose', axis=1).values\n",
        "y = diabetes_df['glucose'].values\n",
        "\n",
        "names = diabetes_df.drop('glucose', axis=1).columns\n",
        "\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso_coef = lasso.fit(X, y).coef_\n",
        "\n",
        "plt.bar(names, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ndYFgmKLrgm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion Matrix**\n",
        "\n",
        "It is a matrix of size 2×2 for binary classification with actual values on one axis and predicted on another.\n",
        "\n",
        "A machine learning model is trained to predict tumor in patients. The test dataset consists of 100 people.\n",
        "\n",
        "**True Positive (TP)** — model correctly predicts the positive class (prediction and actual both are positive). In the above example, 10 people who have tumors are predicted positively by the model.\n",
        "\n",
        "**True Negative (TN)** — model correctly predicts the negative class (prediction and actual both are negative). In the above example, 60 people who don’t have tumors are predicted negatively by the model.\n",
        "\n",
        "**False Positive (FP)** — model gives the wrong prediction of the negative class (predicted-positive, actual-negative). In the above example, 22 people are predicted as positive of having a tumor, although they don’t have a tumor. FP is also called a TYPE I error.\n",
        "\n",
        "**False Negative (FN)** — model wrongly predicts the positive class (predicted-negative, actual-positive). In the above example, 8 people who have tumors are predicted as negative. FN is also called a TYPE II error.\n",
        "\n",
        "With the help of these four values, we can calculate True Positive Rate (TPR), False Negative Rate (FPR), True Negative Rate (TNR), and False Negative Rate (FNR).\n",
        "\n",
        "\n",
        "$ TPR = \\frac{TP}{Actual Positive} = \\frac{TP}{TP + FN}$\n",
        "\n",
        "$ FNR = \\frac{FN}{Actual Positive} = \\frac{FN}{TP + FN}$\n",
        "\n",
        "$ TNR = \\frac{TN}{Actual Negative} = \\frac{TN}{TN + FP}$\n",
        "\n",
        "$ FPR = \\frac{FP}{Actual Negative} = \\frac{FP}{TN + FP}$\n",
        "\n",
        "Even if data is imbalanced, we can figure out that our model is working well or not. For that, **the values of TPR and TNR should be high, and FPR and FNR should be as low as possible.**\n"
      ],
      "metadata": {
        "id": "OZftyI5-SZA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision**\n",
        "\n",
        "Out of all the positive predicted, what percentage is truly positive.\n",
        "\n",
        "$ Precision = \\frac{TP}{TP + FP} $\n",
        "\n",
        "The precision value lies between 0 and 1."
      ],
      "metadata": {
        "id": "NeuBMDzIU6nU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recall**\n",
        "\n",
        "Out of the total positive, what percentage are predicted positive. It is the same as TPR (true positive rate).\n",
        "\n",
        "$ Recall = \\frac{TP}{TP + FN}$"
      ],
      "metadata": {
        "id": "VpRvUB8kVKc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F1 Score**\n",
        "\n",
        "It is the harmonic mean of precision and recall. It takes both false positive and false negatives into account. Therefore, it performs well on an imbalanced dataset.\n",
        "\n",
        "$ F1 score = \\frac{2*(Precision * Recall)}{Precision + Recall} $"
      ],
      "metadata": {
        "id": "5lDBL9OHVrma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix in Scikit-learn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "X_train, X_test, y_train, y_test = \"Split the data\"\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "pred = knn.predict(X_test)\n",
        "\n",
        "print(confustion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "fpy7-Q7_TfXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "4DI3CoLXYDeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "X_train, X_test, y_train, y_test = \"Split the data\"\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "pred = logreg.predict(X_test)\n",
        "\n",
        "# Predicting Probabilites\n",
        "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
        "print(y_pred_probs)"
      ],
      "metadata": {
        "id": "YJbsLE5lYGvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the ROC curve**"
      ],
      "metadata": {
        "id": "XaJjhz2jY-TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.show()\n",
        "\n",
        "# ROC AUC in scikit-learn\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred_probs))"
      ],
      "metadata": {
        "id": "_RbU8Fj_ZBOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter Tuning**\n",
        "- Hyperparameters: Parameters we specify before fitting the model\n",
        "  - Like alpha and n_neighbors"
      ],
      "metadata": {
        "id": "D-eQ6bMANCve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "param_grid = {\"alpha\": np.arrange(0.0001, 1, 10), \"solver\": [\"sag\", \"lsqr\"]}\n",
        "\n",
        "ridge = Ridge()\n",
        "ridge_cv = GridSearchCV(ridge, param_grid, cv=kf)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "print(ridge_cv.best_params_, ridge_cv.best_score_)"
      ],
      "metadata": {
        "id": "PxVPMDj5NREa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limitations and an alternative approach**\n",
        "- 3-fold cv, 1 hyperparameter, 10 total values = 30 fits\n",
        "- 10-fold cv, 3 hyperparameter, 30 total values = 900 fits"
      ],
      "metadata": {
        "id": "edQqXgnNOJfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "param_grid = {\"alpha\": np.arrange(0.0001, 1, 10), \"solver\": [\"sag\", \"lsqr\"]}\n",
        "\n",
        "ridge = Ridge()\n",
        "\n",
        "# Total fit = n_splits * n_iter\n",
        "\n",
        "ridge_cv = RandomizedSearchCV(ridge, param_grid, cv=kf, n_iter=2)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "\n",
        "print(ridge_cv.best_params_, ridge_cv.best_score_)"
      ],
      "metadata": {
        "id": "VFWyBJ6XOY-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dealing with categorical features**\n",
        "\n",
        "- scikit-learn will not accept categorical features by default\n",
        "- Need to convert categorical features into numeric values\n",
        "- Convert to binary features called dummy variables\n",
        "  - 0: Observation was not that category\n",
        "  - 1: Observation was that category"
      ],
      "metadata": {
        "id": "_GYR1z_ZRuCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variables\n",
        "import pandas as pd\n",
        "music_df = pd.read_csv('music_csv')\n",
        "music_dummies = pd.get_dummies(music_df['genre'], drop_first=True)\n",
        "\n",
        "music_dummies = pd.concat([music_df, music_dummies], axis=1)\n",
        "music_dummies = music_dummies.drop('genre', axis=1)\n",
        "\n",
        "\"\"\"\n",
        "If the DataFrame only has one categorical feature, we can pass the entire DataFrame, thus skipping the step of combining variables.\n",
        "If we don't specify a column, the new DataFrame's binary columns will have the original feature name prefixed\n",
        "The categorical column will be automatically dropped\n",
        "\"\"\"\n",
        "music_dummies = pd.get_dummies(music_df, drop_first=True)\n"
      ],
      "metadata": {
        "id": "uGInBcX6SU3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Handling Missing Data**\n",
        "- Drop missing data\n",
        "- Impute missing data\n",
        "\n",
        "**Imputing Values**\n",
        "- Imputation - use subject-matter expertise to replace missing data with educated guesses\n",
        "- Common to use mean\n",
        "- Can also use the median, or another value\n",
        "- For categorical values, we typically use the most frequent value - the mode\n",
        "- Must split our data first before imputing, to avoid data leakage"
      ],
      "metadata": {
        "id": "POT9otHUVfrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation with scikit-learn\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "X_cat = music_df['genre'].values.reshape(-1, 1)\n",
        "X_num = music_df.drop(['genre', 'popularity'], axis=1).values\n",
        "y = music_df['popularity'].values\n",
        "\n",
        "X_train_cat, X_test_cat, y_train_cat, y_test_cat = test_train_split(X_cat, y, test_size=0.2, random_state=12)\n",
        "X_train_num, X_test_num, y_train_num, y_test_num = test_train_split(X_num, y, test_size=0.2, random_state=12)\n",
        "\n",
        "# Impute categorical variable\n",
        "imp_cat = SimpleImputer(strategy='most_frequent')\n",
        "X_train_cat = imp_cat.fit_transform(X_train_cat)\n",
        "X_test_cat = imp_cat.fit_transform(X_test_cat)\n",
        "\n",
        "# Impute numerical variable\n",
        "imp_num = SimpleImputer()\n",
        "X_train_num = imp_num.fit_transform(X_train_num)\n",
        "X_test_num = imp_num.fit_transform(X_test_num)\n",
        "\n",
        "# Combine both imputed data\n",
        "X_train = np.append(X_train_num, X_train_cat, axis=1)\n",
        "X_test = np.append(X_test_num, X_test_cat, axis=1)"
      ],
      "metadata": {
        "id": "Qi6OHyhpWQHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputing with pipelines**\n",
        "\n",
        "We can also impute using a pipeline, which is an object used to run a series of transformations and build a model in a single workflow."
      ],
      "metadata": {
        "id": "q5AIPeNtYXQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "music_df = music_df.dropna(subset=[\"genre\", 'popularity', 'loudness', 'liveness', 'tempo'])\n",
        "music_df['genre'] = np.where(music_df['genre'] == 'Rock', 1, 0)\n",
        "\n",
        "X = music_df.drop('genre', axis=1).values\n",
        "y = music_df['genre'].values\n",
        "\n",
        "steps = [('imputation', SimpleImputer()), (\"logistic_regression\", LogisticRegression())]\n",
        "\n",
        "pipeline = Pipeline(steps)\n",
        "\n",
        "X_train, X_test, y_train, y_test = \"Split the data\"\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "YdxIjQ_lYc9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Centering and Scaling**\n",
        "\n",
        "**Why scale our data?**\n",
        "- Many models use some form of distance to inform them\n",
        "- Features on larger scales can disproprtionately influence the model\n",
        "- Example: KNN uses distance explicitly when making predictions\n",
        "- We want features to be on similar scale\n",
        "- We can normalize or standardize our dataset.\n",
        "\n",
        "**How to scale our data**\n",
        "- Substract the mean and divide by variance\n",
        "  - All features are centered around zero and have a variance of one\n",
        "  - This is called standardization\n",
        "- Can also substract the minimum and divide by the range\n",
        "  - Minimim zero and maximum one\n",
        "- Can also normalize so the data ranges from -1 to +1."
      ],
      "metadata": {
        "id": "nH0uApgj40m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from sklearn.preprocessing import StandardScaler\n",
        "\n",
        " X = music_df.drop('genre', axis=1).values\n",
        " y = music_df['genre'].values\n",
        "\n",
        " X_train, X_test, y_train, y_test = \"Split the data\"\n",
        "\n",
        " scaler = StandardScaler()\n",
        " X_train_scaled = scaler.fit_transform(X_train)\n",
        " X_test_scaled = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "h2XbdElP5xDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating Multiple Models**"
      ],
      "metadata": {
        "id": "O2iCcGm0cqQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "music = pd.read_csv('music_clean.csv')\n",
        "\n",
        "X = music.drop(\"genre\", axis=1).values\n",
        "y = music[\"genre\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {\"Logistic Regression\": LogisticRegression(), \"KNN\": KNeighborsClassifier(), \"Decision Tree\": DecisionTreeClassifier()}\n",
        "results = []\n",
        "\n",
        "for model in models.values():\n",
        "  kf = KFold(n_splits=6, random_state=42, shuffle=True)\n",
        "  cv_results = cross_val_score(model, X_train_scaled, y_train, cv=kf)\n",
        "  results.append(cv_results)\n",
        "\n",
        "plt.boxplot(results, labels=models.keys())\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "eUJzaYZRcuoR",
        "outputId": "c5964a41-5e09-4679-f52d-8b4a3579fe20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test set performance**"
      ],
      "metadata": {
        "id": "1nkYNcd4elsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "  test_score = model.score(X_test_scaled, y_test)\n",
        "  print(\"{} Test Set Accuracy: {}\".format(name, test_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw1Mu-HAeoBj",
        "outputId": "79c0fb6a-28a6-4383-bbb9-e50854dd8ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Set Accuracy: 0.864\n",
            "KNN Test Set Accuracy: 0.888\n",
            "Decision Tree Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}