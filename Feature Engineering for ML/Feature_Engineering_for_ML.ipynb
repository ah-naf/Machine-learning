{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating Features**"
      ],
      "metadata": {
        "id": "92ww40JqDKG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting to know your data**"
      ],
      "metadata": {
        "id": "ZaASTaabDOHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Import so_survey_csv into so_survey_df\n",
        "so_survey_df = pd.read_csv('Combined_DS_v10.csv')\n",
        "\n",
        "# Print the first five rows of the DataFrame\n",
        "print(so_survey_df.head())\n",
        "\n",
        "# Print the data type of each column\n",
        "print(so_survey_df.dtypes)"
      ],
      "metadata": {
        "id": "LSHNQeJODQsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting Specific Data Types**"
      ],
      "metadata": {
        "id": "JweYbLO4Dj9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create subset of only the numeric columns\n",
        "so_numeric_df = so_survey_df.select_dtypes(include=['int', 'float'])\n",
        "\n",
        "# Print the column names contained in so_survey_df_num\n",
        "print(so_numeric_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owYYnxIXDm7x",
        "outputId": "0f094780-cbf5-4f72-8250-35b5202cde6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ConvertedSalary', 'StackOverflowJobsRecommend', 'Age',\n",
            "       'Years Experience'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-hot enocding and dummy variables**"
      ],
      "metadata": {
        "id": "fAPpTAHCE2Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Country column to a one hot encoded Data Frame\n",
        "one_hot_encoded = pd.get_dummies(so_survey_df, columns=['Country'], prefix='OH')\n",
        "\n",
        "# Print the columns names\n",
        "print(one_hot_encoded.columns)\n",
        "\n",
        "\n",
        "# Create dummy variables for the Country column\n",
        "dummy = pd.get_dummies(so_survey_df, columns=['Country'], drop_first=True, prefix='DM')\n",
        "\n",
        "# Print the columns names\n",
        "print(dummy.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1V8hNV5E5JI",
        "outputId": "064a9ce9-21f1-45a6-c994-9d4f1b761be3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
            "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
            "       'Years Experience', 'Gender', 'RawSalary', 'OH_France', 'OH_India',\n",
            "       'OH_Ireland', 'OH_Russia', 'OH_South Africa', 'OH_Spain', 'OH_Sweeden',\n",
            "       'OH_UK', 'OH_USA', 'OH_Ukraine'],\n",
            "      dtype='object')\n",
            "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
            "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
            "       'Years Experience', 'Gender', 'RawSalary', 'DM_India', 'DM_Ireland',\n",
            "       'DM_Russia', 'DM_South Africa', 'DM_Spain', 'DM_Sweeden', 'DM_UK',\n",
            "       'DM_USA', 'DM_Ukraine'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dealing with uncommon categories**"
      ],
      "metadata": {
        "id": "DWjYvSmUFfyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series out of the Country column\n",
        "countries = so_survey_df['Country']\n",
        "\n",
        "# Get the counts of each category\n",
        "country_counts = countries.value_counts()\n",
        "\n",
        "# Create a mask for only categories that occur less than 10 times\n",
        "mask = countries.isin(country_counts[country_counts < 10].index)\n",
        "\n",
        "# Label all other categories as Other\n",
        "countries[mask] = 'Other'\n",
        "\n",
        "# Print the updated category counts\n",
        "print(countries.value_counts())"
      ],
      "metadata": {
        "id": "EFc9s9NgFiLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binarizing Column**"
      ],
      "metadata": {
        "id": "q3QoaeNhGhrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While numeric values can often be used without any feature engineering, there will be cases when some form of manipulation can be useful. For example on some occasions, you might not care about the magnitude of a value but only care about its direction, or if it exists at all. In these situations, you will want to binarize a column. In the `so_survey_df` data, you have a large number of survey respondents that are working voluntarily (without pay). You will create a new column titled `Paid_Job` indicating whether each person is paid (their salary is greater than zero)."
      ],
      "metadata": {
        "id": "1DQVz5NMGpV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Paid_Job column filled with zeros\n",
        "so_survey_df['Paid_Job'] = 0\n",
        "\n",
        "# Replace all the Paid_Job values where ConvertedSalary is > 0\n",
        "so_survey_df.loc[so_survey_df['ConvertedSalary'] > 0, 'Paid_Job'] = 1\n",
        "\n",
        "# Print the first five rows of the columns\n",
        "print(so_survey_df[['Paid_Job', 'ConvertedSalary']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aePXk7pFGvnE",
        "outputId": "b843360c-3782-4ffe-eeb6-5eda266bc67a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Paid_Job  ConvertedSalary\n",
            "0         0              NaN\n",
            "1         1          70841.0\n",
            "2         0              NaN\n",
            "3         1          21426.0\n",
            "4         1          41671.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binning Values**"
      ],
      "metadata": {
        "id": "Hjd66rKHHIaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For many continuous values you will care less about the exact value of a numeric column, but instead care about the bucket it falls into. This can be useful when plotting values, or simplifying your machine learning models. It is mostly used on continuous variables where accuracy is not the biggest concern e.g. age, height, wages.\n",
        "\n",
        "Bins are created using `pd.cut(df['column_name'], bins)` where `bins` can be an integer specifying the number of evenly spaced bins, or a list of bin boundaries."
      ],
      "metadata": {
        "id": "g4sVRm8SHKQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Specify the boundaries of the bins\n",
        "bins = [-np.inf, 10000, 50000, 100000, 150000, np.inf]\n",
        "\n",
        "# Bin labels\n",
        "labels = ['Very low', 'Low', 'Medium', 'High', 'Very high']\n",
        "\n",
        "# Bin the continuous variable ConvertedSalary using these boundaries\n",
        "so_survey_df['boundary_binned'] = pd.cut(so_survey_df['ConvertedSalary'],\n",
        "                                         bins=bins, labels=labels)\n",
        "\n",
        "# Print the first 5 rows of the boundary_binned column\n",
        "print(so_survey_df[['boundary_binned', 'ConvertedSalary']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHPl_q3VHPz3",
        "outputId": "70b56a1f-fd32-4d20-f291-552d88a0d301"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  boundary_binned  ConvertedSalary\n",
            "0             NaN              NaN\n",
            "1          Medium          70841.0\n",
            "2             NaN              NaN\n",
            "3             Low          21426.0\n",
            "4             Low          41671.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dealing wiht Messy Data**"
      ],
      "metadata": {
        "id": "j9CPDUpaVun6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Listwise Deletion**"
      ],
      "metadata": {
        "id": "aVKGizJfX6mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop all rows with missing values in so_survey_df\n",
        "\n",
        "# Create a new DataFrame dropping all incomplete rows\n",
        "no_missing_values_rows = so_survey_df.dropna()\n",
        "\n",
        "# Print the shape of the new DataFrame\n",
        "print(no_missing_values_rows.shape)\n",
        "\n",
        "# Drop all columns with missing values\n",
        "# Create a new DataFrame dropping all columns with incomplete rows\n",
        "no_missing_values_cols = so_survey_df.dropna(how='any', axis=1)\n",
        "\n",
        "# Print the shape of the new DataFrame\n",
        "print(no_missing_values_cols.shape)\n",
        "\n",
        "# Drop all rows in so_survey_df where Gender is missing\n",
        "# Drop all rows where Gender is missing\n",
        "no_gender = so_survey_df.dropna(subset=['Gender'])\n",
        "\n",
        "# Print the shape of the new DataFrame\n",
        "print(no_gender.shape)"
      ],
      "metadata": {
        "id": "WsZOoUevX8yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replacing missing values with constants**"
      ],
      "metadata": {
        "id": "eK0o6wQIYdLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values\n",
        "so_survey_df['Gender'].fillna('Not Given', inplace=True)\n",
        "\n",
        "# Print the count of each value\n",
        "print(so_survey_df['Gender'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbbIOdFrYgQ3",
        "outputId": "47afaaf9-6f46-401e-9195-4292b84fb17c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Male                                                                         632\n",
            "Not Given                                                                    306\n",
            "Female                                                                        53\n",
            "Female;Male                                                                    2\n",
            "Transgender                                                                    2\n",
            "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\n",
            "Male;Non-binary. genderqueer. or gender non-conforming                         1\n",
            "Non-binary. genderqueer. or gender non-conforming                              1\n",
            "Female;Transgender                                                             1\n",
            "Name: Gender, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filling continuous missing values**"
      ],
      "metadata": {
        "id": "uOJF4NCNZZXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the mean\n",
        "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\n",
        "\n",
        "# Round the StackOverflowJobsRecommend values\n",
        "so_survey_df['StackOverflowJobsRecommend'] = round(so_survey_df['StackOverflowJobsRecommend'])\n",
        "\n",
        "# Print the top 5 rows\n",
        "print(so_survey_df['StackOverflowJobsRecommend'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oArA2mRwZc7_",
        "outputId": "0bb97c55-ff46-4c61-82f5-d0239d2f4e9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    7.0\n",
            "1    7.0\n",
            "2    8.0\n",
            "3    7.0\n",
            "4    8.0\n",
            "Name: StackOverflowJobsRecommend, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Percentage based outlier removal**"
      ],
      "metadata": {
        "id": "wbyCj5TJqPSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to ensure a small portion of data is not having an overly adverse effect is by removing a certain percentage of the largest and/or smallest values in the column. This can be achieved by finding the relevant quantile and trimming the data using it with a mask. This approach is particularly useful if you are concerned that the highest values in your dataset should be avoided. When using this approach, you must remember that even if there are no outliers, this will still remove the same top N percentage from the dataset."
      ],
      "metadata": {
        "id": "l3b1Z_6DqRQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the 95th quantile\n",
        "quantile = so_numeric_df['ConvertedSalary'].quantile(0.95)\n",
        "\n",
        "# Trim the outliers\n",
        "trimmed_df = so_numeric_df[so_numeric_df['ConvertedSalary'] < quantile]\n",
        "\n",
        "# The original histogram\n",
        "so_numeric_df[['ConvertedSalary']].hist()\n",
        "plt.show()\n",
        "plt.clf()\n",
        "\n",
        "# The trimmed histogram\n",
        "trimmed_df[['ConvertedSalary']].hist()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4L0ScECMqTT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical outlier removal**"
      ],
      "metadata": {
        "id": "7tVyLLU5q0OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While removing the top N% of your data is useful for ensuring that very spurious points are removed, it does have the disadvantage of always removing the same proportion of points, even if the data is correct. A commonly used alternative approach is to remove data that sits further than three standard deviations from the mean. You can implement this by first calculating the mean and standard deviation of the relevant column to find upper and lower bounds, and applying these bounds as a mask to the DataFrame. This method ensures that only data that is genuinely different from the rest is removed, and will remove fewer points if the data is close together."
      ],
      "metadata": {
        "id": "h8pAy25Rq1MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the mean and standard dev\n",
        "std = so_numeric_df['ConvertedSalary'].std()\n",
        "mean = so_numeric_df['ConvertedSalary'].mean()\n",
        "\n",
        "# Calculate the cutoff\n",
        "cut_off = std * 3\n",
        "lower, upper = mean - cut_off, mean + cut_off\n",
        "\n",
        "# Trim the outliers\n",
        "trimmed_df = so_numeric_df[(so_numeric_df['ConvertedSalary'] < upper) \\\n",
        "                           & (so_numeric_df['ConvertedSalary'] > lower)]\n",
        "\n",
        "# The trimmed box plot\n",
        "trimmed_df[['ConvertedSalary']].boxplot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9zWESo0nq3tJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}