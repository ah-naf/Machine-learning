{"cells":[{"source":"![car](car.jpg)\n\nInsurance companies invest a lot of [time and money](https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf) into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!\n\nKnowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they've asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.\n\nThey have supplied you with their customer data as a csv file called `car_insurance.csv`, along with a table detailing the column names and descriptions below.","metadata":{},"id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e","cell_type":"markdown","attachments":{}},{"source":"\n\n## The dataset\n\n| Column | Description |\n|--------|-------------|\n| `id` | Unique client identifier |\n| `age` | Client's age: <br> <ul><li>`0`: 16-15</li><li>`1`: 26-39</li><li>`2`: 40-64</li><li>`3`: 65+</li></ul> |\n| `gender` | Client's gender: <br> <ul><li>`0`: Female</li><li>`1`: Male</li></ul> |\n| `driving_experience` | Years the client has been driving: <br> <ul><li>`0`: 0-9</li><li>`1`: 10-19</li><li>`2`: 20-29</li><li>`3`: 30+</li></ul> |\n| `education` | Client's level of education: <br> <ul><li>`0`: No education</li><li>`1`: High school</li><li>`2`: University</li></ul> |\n| `income` | Client's income level: <br> <ul><li>`0`: Poverty</li><li>`1`: Working class</li><li>`2`: Middle class</li><li>`3`: Upper class</li></ul> |\n| `credit_score` | Client's credit score (between zero and one) |\n| `vehicle_ownership` | Client's vehicle ownership status: <br><ul><li>`0`: Does not own their vehilce (paying off finance)</li><li>`1`: Owns their vehicle</li></ul> |\n| `vehcile_year` | Year of vehicle registration: <br><ul><li>`0`: Before 2015</li><li>`1`: 2015 or later</li></ul> |\n| `married` | Client's marital status: <br><ul><li>`0`: Not married</li><li>`1`: Married</li></ul> |\n| `children` | Client's number of children |\n| `postal_code` | Client's postal code | \n| `annual_mileage` | Number of miles driven by the client each year |\n| `vehicle_type` | Type of car: <br> <ul><li>`0`: Sedan</li><li>`1`: Sports car</li></ul> |\n| `speeding_violations` | Total number of speeding violations received by the client | \n| `duis` | Number of times the client has been caught driving under the influence of alcohol |\n| `past_accidents` | Total number of previous accidents the client has been involved in |\n| `outcome` | Whether the client made a claim on their car insurance (response variable): <br><ul><li>`0`: No claim</li><li>`1`: Made a claim</li></ul> |","metadata":{},"id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42","cell_type":"markdown"},{"source":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n# Start coding!\ncar_df = pd.read_csv('car_insurance.csv')\ncar_df.info()","metadata":{"executionTime":36,"id":"bA5ajAmk7XH6","lastSuccessfullyExecutedCode":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n# Start coding!\ncar_df = pd.read_csv('car_insurance.csv')\ncar_df.info()\n","executionCancelledAt":null,"lastExecutedAt":1699875416155,"lastScheduledRunId":null},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 18 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   id                   10000 non-null  int64  \n 1   age                  10000 non-null  int64  \n 2   gender               10000 non-null  int64  \n 3   driving_experience   10000 non-null  object \n 4   education            10000 non-null  object \n 5   income               10000 non-null  object \n 6   credit_score         9018 non-null   float64\n 7   vehicle_ownership    10000 non-null  float64\n 8   vehicle_year         10000 non-null  object \n 9   married              10000 non-null  float64\n 10  children             10000 non-null  float64\n 11  postal_code          10000 non-null  int64  \n 12  annual_mileage       9043 non-null   float64\n 13  vehicle_type         10000 non-null  object \n 14  speeding_violations  10000 non-null  int64  \n 15  duis                 10000 non-null  int64  \n 16  past_accidents       10000 non-null  int64  \n 17  outcome              10000 non-null  float64\ndtypes: float64(6), int64(7), object(5)\nmemory usage: 1.4+ MB\n"}]},{"source":"car_df['credit_score'] = car_df['credit_score'].fillna(car_df['credit_score'].mean())\n\ncar_df['annual_mileage'] = car_df['annual_mileage'].fillna(car_df['annual_mileage'].mean())","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1699875497435,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"car_df['credit_score'] = car_df['credit_score'].fillna(car_df['credit_score'].mean())\n\ncar_df['annual_mileage'] = car_df['annual_mileage'].fillna(car_df['annual_mileage'].mean())"},"cell_type":"code","id":"c8396e1e-3975-412c-8022-ed1671bb6cad","execution_count":5,"outputs":[]},{"source":"car_df = car_df.drop('id', axis=1)","metadata":{"executionCancelledAt":null,"executionTime":12,"lastExecutedAt":1699875821487,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"car_df = car_df.drop('id', axis=1)"},"cell_type":"code","id":"81f63f4a-ee07-44a4-a969-0b7777c38c05","execution_count":9,"outputs":[]},{"source":"X = car_df.drop('outcome', axis=1)\ny = car_df['outcome']\n\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns\nnumerical_cols = X.select_dtypes(include=['int64', 'float64']).columns","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1699876391805,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"X = car_df.drop('outcome', axis=1)\ny = car_df['outcome']\n\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns\nnumerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n"},"cell_type":"code","id":"daafe5a3-bdb2-4618-9c02-267f9dd876ca","execution_count":11,"outputs":[]},{"source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\nscaler = StandardScaler()\nohe = OneHotEncoder(handle_unknown='ignore')\n\n# Scale numerical columns\nX_train_num = scaler.fit_transform(X_train[numerical_cols])\nX_test_num = scaler.transform(X_test[numerical_cols])\n\n# One-hot encode categorical columns\nX_train_cat = ohe.fit_transform(X_train[categorical_cols]).toarray()\nX_test_cat = ohe.transform(X_test[categorical_cols]).toarray()\n\n","metadata":{"executionCancelledAt":null,"executionTime":3741,"lastExecutedAt":1699877066972,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\nscaler = StandardScaler()\nohe = OneHotEncoder(handle_unknown='ignore')\n\n# Scale numerical columns\nX_train_num = scaler.fit_transform(X_train[numerical_cols])\nX_test_num = scaler.transform(X_test[numerical_cols])\n\n# One-hot encode categorical columns\nX_train_cat = ohe.fit_transform(X_train[categorical_cols]).toarray()\nX_test_cat = ohe.transform(X_test[categorical_cols]).toarray()\n\n"},"cell_type":"code","id":"bfde6ce9-14ef-492b-a356-b1d435b98af8","execution_count":21,"outputs":[]},{"source":"# Convert to DataFrame\nX_train_num_df = pd.DataFrame(X_train_num, columns=numerical_cols, index=X_train.index)\nX_train_cat_df = pd.DataFrame(X_train_cat, columns=ohe.get_feature_names(categorical_cols), index=X_train.index)\nX_test_num_df = pd.DataFrame(X_test_num, columns=numerical_cols, index=X_test.index)\nX_test_cat_df = pd.DataFrame(X_test_cat, columns=ohe.get_feature_names(categorical_cols), index=X_test.index)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1699877077664,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Convert to DataFrame\nX_train_num_df = pd.DataFrame(X_train_num, columns=numerical_cols, index=X_train.index)\nX_train_cat_df = pd.DataFrame(X_train_cat, columns=ohe.get_feature_names(categorical_cols), index=X_train.index)\nX_test_num_df = pd.DataFrame(X_test_num, columns=numerical_cols, index=X_test.index)\nX_test_cat_df = pd.DataFrame(X_test_cat, columns=ohe.get_feature_names(categorical_cols), index=X_test.index)"},"cell_type":"code","id":"c89b3c8d-2695-4cf0-bbf6-c43029cbeaeb","execution_count":22,"outputs":[]},{"source":"# Combine numerical and categorical columns back into a dataframe\nX_train_preprocessed = pd.DataFrame(X_train_num, columns=numerical_cols).join(pd.DataFrame(X_train_cat, columns=ohe.get_feature_names(categorical_cols)))\nX_test_preprocessed = pd.DataFrame(X_test_num, columns=numerical_cols).join(pd.DataFrame(X_test_cat, columns=ohe.get_feature_names(categorical_cols)))\n","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1699877116300,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Combine numerical and categorical columns back into a dataframe\nX_train_preprocessed = pd.DataFrame(X_train_num, columns=numerical_cols).join(pd.DataFrame(X_train_cat, columns=ohe.get_feature_names(categorical_cols)))\nX_test_preprocessed = pd.DataFrame(X_test_num, columns=numerical_cols).join(pd.DataFrame(X_test_cat, columns=ohe.get_feature_names(categorical_cols)))\n"},"cell_type":"code","id":"05e955f6-a956-4c7e-813c-95aa2e13f762","execution_count":23,"outputs":[]},{"source":"model = LogisticRegression()\nmodel.fit(X_train_preprocessed, y_train)\n\ny_pred = model.predict(X_test_preprocessed)\n","metadata":{"executionCancelledAt":null,"executionTime":235,"lastExecutedAt":1699877437493,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"model = LogisticRegression()\nmodel.fit(X_train_preprocessed, y_train)\n\ny_pred = model.predict(X_test_preprocessed)\n"},"cell_type":"code","id":"8d5bae29-4c9c-4c28-9d31-9a5a89aae5ca","execution_count":32,"outputs":[]},{"source":"from sklearn.metrics import accuracy_score, confusion_matrix\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(confusion_matrix(y_pred, y_test))\nprint(f\"Accuracy of the model: {accuracy:.2f}\")","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1699877553721,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.metrics import accuracy_score, confusion_matrix\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(confusion_matrix(y_pred, y_test))\nprint(f\"Accuracy of the model: {accuracy:.2f}\")","outputsMetadata":{"0":{"height":76,"type":"stream"}}},"cell_type":"code","id":"4b5906f2-483d-4a36-a5d0-45f2939d0215","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":"[[1213  168]\n [ 160  459]]\nAccuracy of the model: 0.84\n"}]},{"source":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# Define models and their hyperparameters\nmodels = {\n    'LogisticRegression': {\n        'model': LogisticRegression(),\n        'params': {\n            'C': np.logspace(-4, 4, 20),\n            'penalty': ['l1', 'l2']\n        }\n    },\n    'RandomForest': {\n        'model': RandomForestClassifier(),\n        'params': {\n            'n_estimators': [10, 50, 100, 200],\n            'max_features': ['auto', 'sqrt', 'log2'],\n            'max_depth': [None, 5, 10, 15, 20]\n        }\n    }\n}\n\n# List for storing best models\nbest_models = []\n\n# Hyperparameter tuning using RandomizedSearchCV\nfor model_name, mp in models.items():\n    random_search = RandomizedSearchCV(mp['model'], mp['params'], n_iter=10, cv=5, scoring='accuracy', random_state=42)\n    random_search.fit(X_train_preprocessed, y_train)\n    best_models.append({\n        'model': model_name,\n        'best_score': random_search.best_score_,\n        'best_params': random_search.best_params_\n    })\n\n# Find the best model\nbest_model = max(best_models, key=lambda x: x['best_score'])\n\nprint(f\"Best Model: {best_model['model']}\")\nprint(f\"Best Score: {best_model['best_score']:.2f}\")\nprint(f\"Best Hyperparameters: {best_model['best_params']}\")\n","metadata":{"executionCancelledAt":null,"executionTime":16677,"lastExecutedAt":1699879071923,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n# Define models and their hyperparameters\nmodels = {\n    'LogisticRegression': {\n        'model': LogisticRegression(),\n        'params': {\n            'C': np.logspace(-4, 4, 20),\n            'penalty': ['l1', 'l2']\n        }\n    },\n    'RandomForest': {\n        'model': RandomForestClassifier(),\n        'params': {\n            'n_estimators': [10, 50, 100, 200],\n            'max_features': ['auto', 'sqrt', 'log2'],\n            'max_depth': [None, 5, 10, 15, 20]\n        }\n    }\n}\n\n# List for storing best models\nbest_models = []\n\n# Hyperparameter tuning using RandomizedSearchCV\nfor model_name, mp in models.items():\n    random_search = RandomizedSearchCV(mp['model'], mp['params'], n_iter=10, cv=5, scoring='accuracy', random_state=42)\n    random_search.fit(X_train_preprocessed, y_train)\n    best_models.append({\n        'model': model_name,\n        'best_score': random_search.best_score_,\n        'best_params': random_search.best_params_\n    })\n\n# Find the best model\nbest_model = max(best_models, key=lambda x: x['best_score'])\n\nprint(f\"Best Model: {best_model['model']}\")\nprint(f\"Best Score: {best_model['best_score']:.2f}\")\nprint(f\"Best Hyperparameters: {best_model['best_params']}\")\n","outputsMetadata":{"0":{"height":95,"type":"stream"}}},"cell_type":"code","id":"8957ff2f-4e4c-4453-a0ab-4d590d564d8f","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":"Best Model: LogisticRegression\nBest Score: 0.85\nBest Hyperparameters: {'penalty': 'l2', 'C': 3792.690190732246}\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}